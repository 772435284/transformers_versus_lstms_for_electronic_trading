{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@Author: Yitao Qiu\n",
    "'''\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "from exp.exp_main import Exp_Main\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "fix_seed = 2021\n",
    "torch.manual_seed(fix_seed)\n",
    "torch.cuda.manual_seed_all(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "from utils.tools import dotdict\n",
    "#parser = argparse.ArgumentParser(description='Autoformer & Transformer family for Time Series Forecasting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.exists('/hy-tmp/crypto.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dotdict()\n",
    "args.is_training=True\n",
    "args.model_id='LOB'\n",
    "args.model = 'Transformer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n",
    "\n",
    "\n",
    "args.data = 'custom' # data\n",
    "args.root_path = '/hy-tmp/' # root path of data file\n",
    "args.data_path = 'crypto.csv' # data file\n",
    "\n",
    "\n",
    "args.features = 'MS' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n",
    "args.target = 'mid_price' # target feature in S or MS task\n",
    "args.freq = 'h' # freq for time features encoding, options:[us,microsecond,s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h\n",
    "args.checkpoints = './checkpoint' # location of model checkpoints\n",
    "\n",
    "args.seq_len = 100 # input sequence length of Informer encoder\n",
    "args.label_len = 50 # start token length of Informer decoder\n",
    "args.pred_len = 100 # prediction sequence length\n",
    "# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n",
    "args.bucket_size= 4 #'for Reformer'\n",
    "args.n_hashes= 4 #'for Reformer'\n",
    "\n",
    "# LSTM\n",
    "args.hidden_size = 64\n",
    "args.num_layers = 2\n",
    "\n",
    "\n",
    "args.individual = False\n",
    "\n",
    "# FEDformer\n",
    "args.version = 'Fourier'\n",
    "args.mode_select = 'random'\n",
    "args.modes = 64\n",
    "args.L = 3\n",
    "args.base = 'legendre'\n",
    "args.cross_activation = 'tanh'\n",
    "args.embed_type = 0\n",
    "\n",
    "args.enc_in = 41 # encoder input size\n",
    "args.dec_in = 41 # decoder input size\n",
    "args.c_out = 1 # output size\n",
    "args.factor = 3 # probsparse attn factor\n",
    "args.d_model = 512 # dimension of model\n",
    "args.n_heads = 8 # num of heads\n",
    "args.e_layers = 2 # num of encoder layers\n",
    "args.d_layers = 1 # num of decoder layers\n",
    "args.d_ff = 2048 # dimension of fcn in model\n",
    "args.moving_avg=25 #'window size of moving average'\n",
    "args.dropout = 0.05 # dropout\n",
    "args.attn = 'prob' # attention used in encoder, options:[prob, full]\n",
    "args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n",
    "args.activation = 'gelu' # activation\n",
    "args.distil = True # whether to use distilling in encoder\n",
    "args.output_attention = False # whether to output attention in ecoder\n",
    "args.mix = True\n",
    "args.padding = 0\n",
    "#args.freq = 'h'\n",
    "args.do_predict =False\n",
    "args.batch_size = 256 \n",
    "args.learning_rate = 0.0001\n",
    "args.loss = 'mse'\n",
    "args.lradj = 'type1'\n",
    "args.use_amp = False # whether to use automatic mixed precision training\n",
    "\n",
    "args.num_workers = 10\n",
    "args.itr = 1\n",
    "args.train_epochs = 10\n",
    "args.patience = 3\n",
    "args.des = 'exp'\n",
    "\n",
    "args.use_gpu = True if torch.cuda.is_available() else False\n",
    "args.gpu = 0\n",
    "\n",
    "args.use_multi_gpu = False\n",
    "args.devices = '0,1,2,3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    args.devices = args.devices.replace(' ','')\n",
    "    device_ids = args.devices.split(',')\n",
    "    args.device_ids = [int(id_) for id_ in device_ids]\n",
    "    args.gpu = args.device_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Args in experiment:')\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp = Exp_Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp = Exp(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, train_loader = exp._get_data(flag='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_x, seq_y, seq_x_mark, seq_y_mark = train_data.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if args.is_training:\n",
    "    for ii in range(args.itr):\n",
    "        # setting record of experiments\n",
    "        setting = '{}_{}_{}_sl{}_ll{}_pl{}_{}'.format(\n",
    "            args.model_id,\n",
    "            args.model,\n",
    "            args.data,\n",
    "            args.seq_len,\n",
    "            args.label_len,\n",
    "            args.pred_len,\n",
    "            ii)\n",
    "\n",
    "        exp = Exp(args)  # set experiments\n",
    "        print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "        exp.train(setting)\n",
    "\n",
    "        print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "        exp.test(setting)\n",
    "\n",
    "        if args.do_predict:\n",
    "            print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "            exp.predict(setting, True)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "else:\n",
    "    ii = 0\n",
    "    setting = '{}_{}_{}_sl{}_ll{}_pl{}_{}'.format(\n",
    "            args.model_id,\n",
    "            args.model,\n",
    "            args.data,\n",
    "            args.seq_len,\n",
    "            args.label_len,\n",
    "            args.pred_len,\n",
    "            ii)\n",
    "\n",
    "    exp = Exp(args)  # set experiments\n",
    "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "    exp.test(setting, test=1)\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('rl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "7daafd6bb215d115716f04f369ff5a8573a2e75f8e14115a37d4c2f7d57b058e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
